{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DATA_FILE = '../spam.csv'\n",
    "df = pd.read_csv(DATA_FILE,encoding='latin-1')\n",
    "print(df.head())\n",
    "\n",
    "tags = df.v1\n",
    "texts = df.v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from keras import metrics\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  3. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  1. ...,  0.  0.  0.]]\n",
      "(5572,) (5572, 1000)\n"
     ]
    }
   ],
   "source": [
    "num_max = 1000\n",
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags)\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)\n",
    "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
    "print(tags[:5])\n",
    "print(mat_texts[:5])\n",
    "print(tags.shape,mat_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 644,097.0\n",
      "Trainable params: 644,097.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "compile done\n",
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.1591 - acc: 0.9533 - binary_accuracy: 0.9533 - val_loss: 0.0599 - val_acc: 0.9857 - val_binary_accuracy: 0.9857\n",
      "Epoch 2/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0296 - acc: 0.9904 - binary_accuracy: 0.9904 - val_loss: 0.0665 - val_acc: 0.9865 - val_binary_accuracy: 0.9865\n",
      "Epoch 3/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0087 - acc: 0.9975 - binary_accuracy: 0.9975 - val_loss: 0.0789 - val_acc: 0.9857 - val_binary_accuracy: 0.9857\n",
      "Epoch 4/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0045 - acc: 0.9987 - binary_accuracy: 0.9987 - val_loss: 0.0925 - val_acc: 0.9874 - val_binary_accuracy: 0.9874\n",
      "Epoch 5/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0027 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.0976 - val_acc: 0.9883 - val_binary_accuracy: 0.9883\n",
      "Epoch 6/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0019 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.0988 - val_acc: 0.9883 - val_binary_accuracy: 0.9883\n",
      "Epoch 7/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0020 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.1176 - val_acc: 0.9883 - val_binary_accuracy: 0.9883\n",
      "Epoch 8/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0021 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.1067 - val_acc: 0.9883 - val_binary_accuracy: 0.9883\n",
      "Epoch 9/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0016 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1138 - val_acc: 0.9883 - val_binary_accuracy: 0.9883\n",
      "Epoch 10/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0014 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1135 - val_acc: 0.9883 - val_binary_accuracy: 0.9883\n",
      "Epoch 11/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0013 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1105 - val_acc: 0.9883 - val_binary_accuracy: 0.9883\n",
      "Epoch 12/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0014 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1140 - val_acc: 0.9883 - val_binary_accuracy: 0.9883\n",
      "Epoch 13/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0013 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1152 - val_acc: 0.9883 - val_binary_accuracy: 0.9883\n",
      "Epoch 14/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0011 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1139 - val_acc: 0.9874 - val_binary_accuracy: 0.9874\n",
      "Epoch 15/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0012 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1147 - val_acc: 0.9874 - val_binary_accuracy: 0.9874\n",
      "Epoch 16/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0012 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1173 - val_acc: 0.9874 - val_binary_accuracy: 0.9874\n",
      "Epoch 17/20\n",
      "4457/4457 [==============================] - 3s - loss: 9.6041e-04 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1188 - val_acc: 0.9883 - val_binary_accuracy: 0.9883\n",
      "Epoch 18/20\n",
      "4457/4457 [==============================] - 3s - loss: 9.5517e-04 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1218 - val_acc: 0.9883 - val_binary_accuracy: 0.9883\n",
      "Epoch 19/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0012 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1188 - val_acc: 0.9848 - val_binary_accuracy: 0.9848\n",
      "Epoch 20/20\n",
      "4457/4457 [==============================] - 3s - loss: 0.0012 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1305 - val_acc: 0.9839 - val_binary_accuracy: 0.9839\n"
     ]
    }
   ],
   "source": [
    "# try a simple model first\n",
    "\n",
    "def get_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(num_max,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',metrics.binary_accuracy])\n",
    "    print('compile done')\n",
    "    return model\n",
    "\n",
    "def check_model(model,x,y):\n",
    "    model.fit(x,y,batch_size=32,epochs=20,verbose=1,validation_split=0.2)\n",
    "\n",
    "m = get_simple_model()\n",
    "check_model(m,mat_texts,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 478, 875, 784, 669, 65, 8, 89, 122, 352, 148, 67, 58, 144]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  50 478 875 784\n",
      " 669  65   8  89 122 352 148  67  58 144]\n",
      "(5572, 100)\n"
     ]
    }
   ],
   "source": [
    "# for cnn preproces\n",
    "max_len = 100\n",
    "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
    "print(cnn_texts_seq[0])\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "print(cnn_texts_mat[0])\n",
    "print(cnn_texts_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 20)           20000     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 64)            3904      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,801.0\n",
      "Trainable params: 40,801.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.4085 - acc: 0.8649 - binary_accuracy: 0.8649 - val_loss: 0.2868 - val_acc: 0.8700 - val_binary_accuracy: 0.8700\n",
      "Epoch 2/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.2320 - acc: 0.8878 - binary_accuracy: 0.8878 - val_loss: 0.2008 - val_acc: 0.9184 - val_binary_accuracy: 0.9184\n",
      "Epoch 3/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.1326 - acc: 0.9612 - binary_accuracy: 0.9612 - val_loss: 0.0550 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 4/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0438 - acc: 0.9881 - binary_accuracy: 0.9881 - val_loss: 0.0522 - val_acc: 0.9857 - val_binary_accuracy: 0.9857\n",
      "Epoch 5/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0261 - acc: 0.9930 - binary_accuracy: 0.9930 - val_loss: 0.0609 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 6/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0198 - acc: 0.9951 - binary_accuracy: 0.9951 - val_loss: 0.0586 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 7/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0135 - acc: 0.9962 - binary_accuracy: 0.9962 - val_loss: 0.0678 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 8/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0102 - acc: 0.9975 - binary_accuracy: 0.9975 - val_loss: 0.0727 - val_acc: 0.9785 - val_binary_accuracy: 0.9785\n",
      "Epoch 9/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0095 - acc: 0.9966 - binary_accuracy: 0.9966 - val_loss: 0.0772 - val_acc: 0.9803 - val_binary_accuracy: 0.9803\n",
      "Epoch 10/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0072 - acc: 0.9978 - binary_accuracy: 0.9978 - val_loss: 0.0819 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 11/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0058 - acc: 0.9989 - binary_accuracy: 0.9989 - val_loss: 0.0883 - val_acc: 0.9785 - val_binary_accuracy: 0.9785\n",
      "Epoch 12/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0066 - acc: 0.9978 - binary_accuracy: 0.9978 - val_loss: 0.0902 - val_acc: 0.9794 - val_binary_accuracy: 0.9794\n",
      "Epoch 13/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0041 - acc: 0.9989 - binary_accuracy: 0.9989 - val_loss: 0.0949 - val_acc: 0.9767 - val_binary_accuracy: 0.9767\n",
      "Epoch 14/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0031 - acc: 0.9993 - binary_accuracy: 0.9993 - val_loss: 0.1017 - val_acc: 0.9767 - val_binary_accuracy: 0.9767\n",
      "Epoch 15/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0039 - acc: 0.9989 - binary_accuracy: 0.9989 - val_loss: 0.1091 - val_acc: 0.9776 - val_binary_accuracy: 0.9776\n",
      "Epoch 16/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0033 - acc: 0.9991 - binary_accuracy: 0.9991 - val_loss: 0.1191 - val_acc: 0.9776 - val_binary_accuracy: 0.9776\n",
      "Epoch 17/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0029 - acc: 0.9993 - binary_accuracy: 0.9993 - val_loss: 0.1214 - val_acc: 0.9767 - val_binary_accuracy: 0.9767\n",
      "Epoch 18/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0027 - acc: 0.9991 - binary_accuracy: 0.9991 - val_loss: 0.1172 - val_acc: 0.9749 - val_binary_accuracy: 0.9749\n",
      "Epoch 19/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0025 - acc: 0.9993 - binary_accuracy: 0.9993 - val_loss: 0.1225 - val_acc: 0.9767 - val_binary_accuracy: 0.9767\n",
      "Epoch 20/20\n",
      "4457/4457 [==============================] - 2s - loss: 0.0022 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.1229 - val_acc: 0.9794 - val_binary_accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "def get_cnn_model_v1():   \n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "m = get_cnn_model_v1()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 50)           50000     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 98, 64)            9664      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 76,561.0\n",
      "Trainable params: 76,561.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/20\n",
      "4457/4457 [==============================] - 5s - loss: 0.3721 - acc: 0.8595 - binary_accuracy: 0.8595 - val_loss: 0.2381 - val_acc: 0.8709 - val_binary_accuracy: 0.8709\n",
      "Epoch 2/20\n",
      "4457/4457 [==============================] - 4s - loss: 0.0982 - acc: 0.9688 - binary_accuracy: 0.9688 - val_loss: 0.0449 - val_acc: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 3/20\n",
      "4457/4457 [==============================] - 4s - loss: 0.0336 - acc: 0.9901 - binary_accuracy: 0.9901 - val_loss: 0.0449 - val_acc: 0.9848 - val_binary_accuracy: 0.9848\n",
      "Epoch 4/20\n",
      "4457/4457 [==============================] - 4s - loss: 0.0204 - acc: 0.9951 - binary_accuracy: 0.9951 - val_loss: 0.0479 - val_acc: 0.9857 - val_binary_accuracy: 0.9857\n",
      "Epoch 5/20\n",
      "4457/4457 [==============================] - 4s - loss: 0.0158 - acc: 0.9957 - binary_accuracy: 0.9957 - val_loss: 0.0522 - val_acc: 0.9874 - val_binary_accuracy: 0.9874\n",
      "Epoch 6/20\n",
      "4457/4457 [==============================] - 4s - loss: 0.0096 - acc: 0.9978 - binary_accuracy: 0.9978 - val_loss: 0.0557 - val_acc: 0.9865 - val_binary_accuracy: 0.9865\n",
      "Epoch 7/20\n",
      "4457/4457 [==============================] - 4s - loss: 0.0083 - acc: 0.9980 - binary_accuracy: 0.9980 - val_loss: 0.0561 - val_acc: 0.9848 - val_binary_accuracy: 0.9848\n",
      "Epoch 8/20\n",
      "4457/4457 [==============================] - 5s - loss: 0.0074 - acc: 0.9978 - binary_accuracy: 0.9978 - val_loss: 0.0701 - val_acc: 0.9803 - val_binary_accuracy: 0.9803\n",
      "Epoch 9/20\n",
      "4457/4457 [==============================] - 4s - loss: 0.0050 - acc: 0.9989 - binary_accuracy: 0.9989 - val_loss: 0.0744 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 10/20\n",
      "4457/4457 [==============================] - 5s - loss: 0.0041 - acc: 0.9989 - binary_accuracy: 0.9989 - val_loss: 0.0741 - val_acc: 0.9848 - val_binary_accuracy: 0.9848\n",
      "Epoch 11/20\n",
      "4457/4457 [==============================] - 5s - loss: 0.0051 - acc: 0.9982 - binary_accuracy: 0.9982 - val_loss: 0.0753 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 12/20\n",
      "4457/4457 [==============================] - 5s - loss: 0.0036 - acc: 0.9991 - binary_accuracy: 0.9991 - val_loss: 0.0837 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 13/20\n",
      "4457/4457 [==============================] - 5s - loss: 0.0022 - acc: 0.9993 - binary_accuracy: 0.9993 - val_loss: 0.0845 - val_acc: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 14/20\n",
      "4457/4457 [==============================] - 5s - loss: 0.0019 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.0878 - val_acc: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 15/20\n",
      "4457/4457 [==============================] - 5s - loss: 0.0020 - acc: 0.9993 - binary_accuracy: 0.9993 - val_loss: 0.0910 - val_acc: 0.9803 - val_binary_accuracy: 0.9803\n",
      "Epoch 16/20\n",
      "4457/4457 [==============================] - 5s - loss: 0.0019 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.0924 - val_acc: 0.9794 - val_binary_accuracy: 0.9794\n",
      "Epoch 17/20\n",
      "4457/4457 [==============================] - 5s - loss: 0.0014 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.0940 - val_acc: 0.9794 - val_binary_accuracy: 0.9794\n",
      "Epoch 18/20\n",
      "4457/4457 [==============================] - 5s - loss: 0.0013 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.0938 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 19/20\n",
      "4457/4457 [==============================] - 5s - loss: 0.0014 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.0963 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 20/20\n",
      "4457/4457 [==============================] - 6s - loss: 0.0015 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.0951 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "def get_cnn_model_v2(): # added embed   \n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        50, #!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "m = get_cnn_model_v2()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 20)           20000     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 98, 256)           15616     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 101,665.0\n",
      "Trainable params: 101,665.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.3706 - acc: 0.8649 - binary_accuracy: 0.8649 - val_loss: 0.2431 - val_acc: 0.8700 - val_binary_accuracy: 0.8700\n",
      "Epoch 2/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.1913 - acc: 0.9195 - binary_accuracy: 0.9195 - val_loss: 0.0675 - val_acc: 0.9767 - val_binary_accuracy: 0.9767\n",
      "Epoch 3/20\n",
      "4457/4457 [==============================] - 6s - loss: 0.0562 - acc: 0.9843 - binary_accuracy: 0.9843 - val_loss: 0.0480 - val_acc: 0.9857 - val_binary_accuracy: 0.9857\n",
      "Epoch 4/20\n",
      "4457/4457 [==============================] - 6s - loss: 0.0326 - acc: 0.9910 - binary_accuracy: 0.9910 - val_loss: 0.0492 - val_acc: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 5/20\n",
      "4457/4457 [==============================] - 6s - loss: 0.0238 - acc: 0.9935 - binary_accuracy: 0.9935 - val_loss: 0.0567 - val_acc: 0.9848 - val_binary_accuracy: 0.9848\n",
      "Epoch 6/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0169 - acc: 0.9953 - binary_accuracy: 0.9953 - val_loss: 0.0618 - val_acc: 0.9848 - val_binary_accuracy: 0.9848\n",
      "Epoch 7/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0125 - acc: 0.9964 - binary_accuracy: 0.9964 - val_loss: 0.0678 - val_acc: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 8/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0106 - acc: 0.9978 - binary_accuracy: 0.9978 - val_loss: 0.0668 - val_acc: 0.9848 - val_binary_accuracy: 0.9848\n",
      "Epoch 9/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0097 - acc: 0.9978 - binary_accuracy: 0.9978 - val_loss: 0.0752 - val_acc: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 10/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0075 - acc: 0.9980 - binary_accuracy: 0.9980 - val_loss: 0.0826 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 11/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0086 - acc: 0.9971 - binary_accuracy: 0.9971 - val_loss: 0.0934 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 12/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0057 - acc: 0.9987 - binary_accuracy: 0.9987 - val_loss: 0.0963 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 13/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0057 - acc: 0.9987 - binary_accuracy: 0.9987 - val_loss: 0.1014 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 14/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0039 - acc: 0.9984 - binary_accuracy: 0.9984 - val_loss: 0.1016 - val_acc: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 15/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0057 - acc: 0.9987 - binary_accuracy: 0.9987 - val_loss: 0.1096 - val_acc: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 16/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0037 - acc: 0.9991 - binary_accuracy: 0.9991 - val_loss: 0.0999 - val_acc: 0.9857 - val_binary_accuracy: 0.9857\n",
      "Epoch 17/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0022 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.1101 - val_acc: 0.9848 - val_binary_accuracy: 0.9848\n",
      "Epoch 18/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0027 - acc: 0.9993 - binary_accuracy: 0.9993 - val_loss: 0.1239 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 19/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0022 - acc: 0.9993 - binary_accuracy: 0.9993 - val_loss: 0.1298 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 20/20\n",
      "4457/4457 [==============================] - 7s - loss: 0.0027 - acc: 0.9991 - binary_accuracy: 0.9991 - val_loss: 0.1255 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "def get_cnn_model_v3():    # added filter\n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(256, #!!!!!!!!!!!!!!!!!!!\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "m = get_cnn_model_v3()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
